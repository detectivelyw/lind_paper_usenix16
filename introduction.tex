\section{Introduction}
\label{sec.introduction}

To run multiple applications on a computer, it is critical to securely
manage access to the machine's underlying hardware. In modern computer systems,
either a hypervisor - a virtual machine monitor (VMM), or an
operating system (OS) kernel performs this important function. Unfortunately,
code within an OS kernel may contain flaws and vulnerabilities that can be
triggered in an attack by a malicious adversary. If this occurs, an attacker
could have unrestricted access to the system.

%One critical flaw, discovered in the Linux kernel in the \texttt{futex} subsystem call can allow an attacker to
%gain ring 0 control via the \texttt{futex} syscall, and potentially execute arbitrary code
%with kernel mode privileges~\cite{CVE-2014-3153}. \cappos{Possibly omit this sentence.}

A diverse set of defensive technologies, including OS virtualization (e.g., Xen,
 KVM, VirtualBox), system call filtering \cite{Janus:99},\cite{SCI-04},
and library OSes \cite{Bascule},\cite{Drawbridge-11}, have been developed to
protect OS kernels. Common security wisdom holds that running software in a
virtual machinecan prevent an attacker from exploiting flaws in the underlying
kernel.
However, exactly how secure is virtualization? \cite{Tal}. As we will
demonstrate in this paper, even with virtualization techniques employed, one
third of the vulnerabilities in the Linux kernel are still vulnerable to exploitation./lois{Can this paragraph be somewhat shortened, or maybe combined or eliminated?. Is the fact that Lind is a "virtualized" system important
enough to give it a full paragraph?}

\lois{transition is needed here. There is no connection made between virtualization techniques and where kernel vulnerabilities exist} In this paper, we develop a
metric that helps to identify likely locations within the kernel
where vulnerabilities may lie.
For this purpose, we examined 40 kernel patches designed to fix severe Linux
kernel security bugs and analyzed the lines where those bugs occurred.
The results show that kernel paths used by popular applications contain fewer
security bugs, and therefore, can be exposed with less risk.

However, limiting access to kernel code by itself is insufficent to build a secure virtualization system.
First, if a complex program can not access part of the kernel, its functionality
 must exist somewhere else or the program will not work.  Second, it is
typical for virtualization systems to add new privileged code.
As a result, a vulnerability in the privileged codebase is as much of a security
risk as a flaw in the kernel.  %However, this privileged code needs to be
%complex because the system must implement complex
% must exist somewhere or else applications will not run.
For example, CVE-2008-2100, a vulnerability in VMWare's codebase that was caused by buffer overflows
%~\cite{CVE-2008-2100}
in the VIX API and it could allow local users to bypass the guest VM and gain privilege escalation to execute arbitrary code
in the host OS, even shellcode to access the kernel of the host OS. CVE-2011-1751 was another bug due to
missing check in KVM's QEMU emulation of PCI-ISA bridge. This enables an attacker to utilize other techniques \cite{Virtunoid}
for root exploit in the host OS being triggered from a guest.
%\cappos{Revise this paragraph further}\lois{as we discussed, replace these two vague examples with one example described in more detail}


%To address this issue,
To this end, we propose a new design for virtualization
systems called ``safely-reimplement'' that restricts access to only the
kernel paths that are mostly used by common applications. \lois{for all vrtualization systems?} To restrict the privileged
code, we first build a minimal, sandboxed environment that also only uses
common kernel paths.
We then implement a POSIX interface inside of this safe sandbox. For complex and dangerous system functions,
which may access the risky portion of the kernel,
input to POSIX is reimplemented by our own code within a sandbox. Any bugs or failures within the implementation of
those complex system functions
will be contained by the sandbox, and will not have the chance to reach
and trigger risky portions of the kernel. Because of this added security, we dub this as a "safe-reimplementation" design.
Therefore, even if the code
is vulnerable to an attack, it is unable to trigger
kernel paths that are less commonly used or tested.\lois{I think this paragraph needs to be simplified. I think the level of detail is too high for an introduction paragraph}

This new design helped us to understand which kernel paths are hardest to
safely-reimplement and provided key insights about what kernel paths system
designers should give the highest degree of scrutiny.
In turn, we then use this design paradigm to develop
a virtualization system called Lind.\lois{and Lind is developed to do what? Is it just another virtualization system?}
Lind uses Google Native client for software fault isolation (memory
safety of the application) and the Repy sandbox~\cite{Repy-10} to contain the POSIX
implementation and to provide access to the kernel.

To evaluate the effectiveness of Lind, we first captured the
kernel traces from user programs run in Lind and four other virtualization
systems.
%and compare their kernel traces.
These traces were then compared against historical
kernel bug reports to verify which trace was more likely to trigger bugs.
Results showed that applications run in Lind were the least likely to
trigger kernel bugs, with only one out of the 35 kernel vulnerabilities tested
being found for an effectiveness rate of 2.9\%. In contrast, the virtualization
systems built without our metric triggered more vulnerabilities (23-40\%). This
suggests that our metric can help effectively design and build more secure
virtualization systems.

In summary, \lois{I inserted "in summary," but I don't think this is quite enough.
A transition is needed} the main contributions of this paper are as follows: %\cappos{revise}
\begin{itemize}
\item We propose and test a novel metric for quantitatively measuring and
evaluating the security of privileged code, such as in an OS kernel.
The proposed metric examines the safety of the kernel trace at the lines-of-code
level.
%\yanyan{what is "generated by producing design recommendations"?}
\item We validate the key hypothesis that commonly used kernel paths contain
fewer bugs, as predicted by our metric.

\item We use the metric to build a secure ``safely-reimplement'' design that
involves reimplementation of risky system calls inside a
sandbox that only uses safe kernel paths.
%that commonly used kernel paths contain fewer bugs.

\item With this new design, we implement a sandbox security system called Lind
that provides a secure environment for applications and strong protection for
the kernel.
\item We implement Lind and find \gholami{I think this is not a contribution
rather it is more results of evaulations}
it triggers only one (2.9\%) of the kernel vulnerabilities we examined. This
suggests that our metric can help design and build virtualization systems
with greater security.
\end{itemize}
\cappos{Quantitative analysis for sandboxes}

The remainder of this paper is organized as follows.
Section \ref{sec.motivation-and-background} describes the motivation that drove our work and key background material.
Section \ref{sec.metric}, introduces the proposed kernel security metric. The
``safely-reimplement'' design pattern derived from this metric is then discussed in Section \ref{sec.design}. Section \ref{sec.implementation},
explains the significant features of Lind, the kernel security system developed
from the design pattern explained in the previous section. In Section \ref{sec.evaluation} the security and efficiency of Lind is tested against other virtualization systems. Section \ref{sec.limitation} outlines the current
limitations of the Lind prototype and possible future initiatives.
Finally, Section \ref{sec.related_work} reviews existing tools and techniques that share
Lind's security techniques and goals, and we conclude our remarks in
Section \ref{sec.conclusion}.
